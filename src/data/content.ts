// This file is auto-generated. Do not edit manually.
// Generated at: 2025-12-04T23:23:46.622Z

export interface BlogPost {
  slug: string;
  title: string;
  excerpt: string;
  content: string;
  contentHtml: string;
  author: string;
  date: string;
  readTime: number;
  category: string;
  tags: string[];
  image: string;
  featured: boolean;
}

export interface ProjectPost {
  slug: string;
  title: string;
  excerpt: string;
  content: string;
  contentHtml: string;
  image: string;
  technologies: string[];
  githubUrl: string;
  liveUrl: string;
  date: string;
  category: string;
  featured: boolean;
}

export const blogPosts: BlogPost[] = [
  {
    "slug": "zero-shot-to-production-image-classification",
    "title": "From Zero-Shot to Production: A Practical Image Classification Workflow",
    "excerpt": "How I built a lightweight ML system to classify 45k+ vendor product images using zero-shot CLIP, classical ML, and active learning - applied, grounded, and shaped by what I've learned in school and at work.",
    "content": "\r\n# From Zero-Shot to Production: A Practical Image Classification Workflow\r\n\r\n## Introduction\r\n\r\nThis project started with a simple internal question:\r\n\r\n**Can we automatically separate packaged vs. unpackaged product images in our catalog?**\r\n\r\nVendors often send us ZIP files containing tens of thousands of mixed images - packaged shots, loose items, lifestyle photos, renders, and close-ups. There's no metadata, no naming structure, and no consistency.\r\n\r\nManually sorting 45,000+ images wasn't realistic.\r\nInstead of treating this as a full \"ML initiative,\" I approached it the way I've tackled projects in my homelab or at school:\r\n\r\n* start simple\r\n* build only what's needed\r\n* iterate as you learn\r\n* keep the system practical\r\n\r\nThat mindset led to a lightweight ML workflow that handled the entire dataset with only a few hundred human labels.\r\n\r\n---\r\n\r\n## TLDR\r\n\r\nI built a small internal ML system that uses:\r\n\r\n- **Zero-shot OpenCLIP embeddings** to start with no labels\r\n- **A Logistic Regression classifier** for fast supervised learning\r\n- **Decision fusion:** zero-shot + classifier + clustering\r\n- **Embedding caching + batch GPU inference** for efficiency\r\n- **Active learning** to reduce labeling effort\r\n- **Two lightweight UIs** (Qt + Flask) for quick labeling\r\n\r\nIt wasn't a huge project - but it solved a real internal bottleneck and helped me sharpen applied ML engineering skills.\r\n\r\n---\r\n\r\n# System Setup at a Glance\r\n\r\n- `IMAGE_DIR=all_images`, outputs copied to `classified/packaged` and `classified/unpackaged`\r\n- Embeddings cached in `image_embeds_cache.pkl` with model/pretrained stamped to avoid stale reuse\r\n- Labels stored in `labeled_images.pkl`, classifier in `trained_classifier.pkl`\r\n- Adaptive batching: defaults to 16 on GPU, 8 on CPU to balance throughput and memory\r\n- Confidence guardrails: `CONFIDENCE_MARGIN=1.10`, active-learning queue capped at 1,000 per session\r\n- Runs on CUDA if available, otherwise CPU; web UI via Flask, desktop UI via PySide6 Qt\r\n\r\n---\r\n\r\n# Step 1: Starting With Zero-Shot CLIP\r\n\r\nBecause we had _zero_ labeled images, I began with **OpenCLIP ViT-H-14**.\r\n\r\nI created simple text prompts to anchor packaged vs. unpackaged semantics:\r\n\r\n```python\r\npackaged_prompts = [\r\n    \"a product in packaging\",\r\n    \"a boxed product\",\r\n    \"retail packaging\",\r\n]\r\n\r\nunpackaged_prompts = [\r\n    \"a product without packaging\",\r\n    \"product only, no box\",\r\n    \"item removed from packaging\",\r\n]\r\n```\r\n\r\nCLIP converts these into text embeddings:\r\n\r\n```python\r\nwith torch.no_grad():\r\n    text_tokens = tokenizer(all_prompts).to(device)\r\n    text_features = model.encode_text(text_tokens)\r\n    text_features /= text_features.norm(dim=-1, keepdim=True)\r\n```\r\n\r\nAt this stage, zero-shot predictions were rough but surprisingly useful.\r\nThey formed the starting point for active learning and gave the first signal for classification (the zero-shot step is text–image similarity; the Logistic Regression later uses the image embeddings, not a “zero-shot embedding”).\r\n\r\nImplementation notes:\n\n- Model: `open_clip.create_model_and_transforms(\"ViT-H-14\", \"laion2b_s32b_b79k\")`\n- Tokenization and encoding happen once at startup; embeddings are L2-normalized for clean cosine sims\n- Runs in half precision on GPU for speed; AMP autocast mainly benefits GPU paths (it does not speed up CPU)\n- CLIP packaging semantics are prompt-sensitive; packaging vs. unpackaged is not a native class, so prompts need tuning and still fluctuate\n\n![CLIP architecture sketch showing dual encoders](/images/zero-shot-to-production-image-classification/clip_architecture_sketch.png)\n*Source: Pinecone guide to multi-modal ML with CLIP.*\n\n![CLIP contrastive pretraining and zero-shot pipeline](/images/zero-shot-to-production-image-classification/clip_pipeline_combined.png)\n*Source: LearnOpenCV CLIP tutorial.*\n\n---\n\n# Step 2: Adding a Lightweight Supervised Layer\n\nOnce I labeled a small set of examples, I trained a **Logistic Regression classifier** on the CLIP embeddings:\n\r\n```python\r\nclf = LogisticRegression(max_iter=2000)\r\nclf.fit(X_train, y_train)\r\n```\r\n\r\nThis was intentional:\r\n\r\n- it trains fast\r\n- it works well on small datasets\r\n- it updates instantly\r\n- no GPU required\r\n\nIt quickly began outperforming zero-shot predictions, even with <200 labeled samples. The probabilities are not calibrated (especially with few labels), so they are best treated as relative scores, not ground-truth confidence.\n\nPersistence and guardrails:\n\n- Labels are saved to `labeled_images.pkl`; classifier is persisted to `trained_classifier.pkl`\n- Training only kicks in after at least 10 samples with both classes represented\n- The Qt and web labelers retrain every 10 labels so the model keeps getting sharper during a session\n\n![Logistic sigmoid curve](/images/zero-shot-to-production-image-classification/logistic_curve.png)\n*Source: Wikimedia Commons (“Logistic-curve.svg”).*\n\n---\n\n# Step 3: Decision Fusion\n\r\nVendor data is extremely inconsistent. Images vary in lighting, angle, background, and composition.\r\n\r\nTo stabilize predictions, I combined three signals:\r\n\r\n1. **Zero-shot confidence**\r\n2. **Classifier probability**\r\n3. **KMeans cluster prior**\r\n\r\nThe fusion logic looked like this:\r\n\r\n```python\r\nif clf is not None:\r\n    prob_packaged = clf.predict_proba(feat.reshape(1, -1))[0, 1]\r\n    return \"packaged\" if prob_packaged >= 0.5 else \"unpackaged\"\r\n\r\nzs_label, sims = zero_shot_label(feat)\r\ncluster = cluster_labels[idx]\r\n\r\n# fallback heuristics\r\nif zs_packaged and cluster_is_packaged:\r\n    return \"packaged\"\r\nif (not zs_packaged) and (not cluster_is_packaged):\r\n    return \"unpackaged\"\r\n```\r\n\r\nThis was a simple but effective way to resolve ambiguity and smooth out noisy cases.\r\n\nDetails:\n\n- KMeans (k=2) runs over all embeddings once per session; the cluster with higher similarity to packaged prompts becomes the packaged prior\n- When a trained classifier exists, it currently takes precedence; otherwise fusion falls back to zero-shot + clusters with a small confidence margin (`1.10` multiplies the stronger signal before accepting it)\n- True fusion is not implemented yet; blending all signals when LR is near 0.5 would be more robust than hard precedence\n\n![KMeans convergence illustration](/images/zero-shot-to-production-image-classification/kmeans_convergence.png)\n*Source: Wikipedia K-means clustering article (convergence example).*\n\n---\n\n# Step 4: Scaling With Embedding Caching & Batch Inference\n\r\nComputing embeddings for 45k images is expensive.\r\nRecomputing them every run would have been painful.\r\n\r\nSo I built a persistent caching layer:\r\n\r\n```python\r\nif os.path.exists(EMBED_CACHE_PATH):\r\n    cache = pickle.load(f)\r\n    embeds = cache.get(\"embeds\", {})\r\n```\r\n\r\nIt detects:\r\n\r\n- images missing from cache\r\n- stale entries where the file was deleted\r\n- model changes that require invalidation\r\n\r\nWhen embedding new images, I switched to **batched GPU inference**:\r\n\r\n```python\r\nwith torch.no_grad(), torch.cuda.amp.autocast():\r\n    feats = model.encode_image(batch_tensor)\r\n    feats /= feats.norm(dim=-1, keepdim=True)\r\n```\r\n\r\nThis alone sped up processing from hours to minutes.\r\n\r\nThe embedding manager also:\r\n\r\n- Detects missing/stale files and prompts whether to embed only missing files or re-embed everything\r\n- Logs throughput and saves file order alongside embeddings so downstream steps stay aligned\r\n- Uses batched tensor stacks to keep the GPU/CPU busy instead of looping image-by-image\r\n- Model stamping avoids stale reuse across model changes, but it does not hash images; if files change without renaming, a hash/mtime check would be required for full staleness detection\r\n\r\n---\r\n\r\n# Step 5: Active Learning to Reduce Labeling\n\nLabeling is the real bottleneck.\nTo minimize the amount of manual labeling, I ranked images by **uncertainty**:\n\r\n```python\r\nuncertainties = np.abs(probs[:, 1] - 0.5)\r\nidxs = np.argsort(uncertainties)\r\n```\r\n\r\nImages closest to 0.5 probability are the most valuable to label.\r\n\r\nEvery 10 labels, the classifier retrained:\r\n\r\n```python\r\nif len(label_db) % 10 == 0:\r\n    clf = train_classifier_from_labels(embeds, label_db)\r\n```\r\n\r\nThis feedback loop dramatically reduced labeling effort.\r\nA few hundred labels were enough for strong performance across all 45k images.\r\n\r\nHow the queue is built:\r\n\r\n- Keeps a session-scoped queue up to 1,000 items\r\n- If a classifier exists, it sorts by uncertainty (closest to 0.5) so every label delivers maximum lift (the variable is named `uncertainties`, but it is really a distance-from-0.5 score; smaller means more uncertain—the naming is inverted)\n- Falls back to random sampling when no classifier is available yet\n- Global stats (confidence rate, packaged ratio, average margin) are computed upfront to give labeling context\n\n![Active learning loop diagram](/images/zero-shot-to-production-image-classification/active_learning_diagram.png)\n*Source: Neptune AI (diagram of active learning system).*\n\n---\n\r\n# Step 6: Building Helpful Labeling Tools\r\n\r\nTwo simple UIs made the workflow much more usable:\r\n\r\n## Qt Desktop App\r\n\r\n```python\r\nself.info_label.setText(\r\n    f\"{fname}\\nPrediction: {pred} ({prob*100:.1f}%)\\nZero-shot: {zs_prob*100:.1f}%\"\r\n)\r\n```\r\n\r\nFast, responsive, and keyboard-friendly.\r\n\r\n## Flask Web Dashboard\r\n\r\n```python\r\n@app.route(\"/label\", methods=[\"POST\"])\r\ndef label():\r\n    label_db[fname] = request.form.get(\"label\")\r\n    save_label_db(label_db)\r\n```\r\n\r\nAccessible to anyone without installation.\r\n\r\nThis made labeling collaborative and painless.\r\n\r\nQuality-of-life touches:\r\n\r\n- Qt UI shows prediction, zero-shot confidence, packaged ratio, and dataset-level stats; retrains every 10 labels\r\n- Web UI serves images directly from disk (`/_img/<filename>`) and retrains periodically without restarting the server\r\n\r\n---\r\n\r\n# Batch Classification Path\r\n\r\nWhen labeling is done (or when you just want a quick pass), batch mode runs end-to-end:\r\n\r\n1. Load or build embeddings (reusing cache)\r\n2. Load labels and classifier; retrain if new labels are present\r\n3. Run KMeans for cluster priors\r\n4. Decide packaged/unpackaged for every file using classifier-first, then zero-shot + clusters\r\n5. Copy images into `classified/packaged` and `classified/unpackaged`\r\n\r\n---\r\n\r\n# Caveats and Future Fixes\r\n\r\n- True fusion: the current logic lets the Logistic Regression call the shot even at 0.501 probability; a better approach would down-weight LR when it is near 0.5 and lean on zero-shot + clusters in that band.\r\n- Cluster prior: the k=2 KMeans prior is unvalidated; if clusters track background color instead of packaging, it can hurt accuracy. A simple guard would be to check cluster-packaged alignment against a labeled sample before using it.\r\n- Naming clarity: the active-learning score called `uncertainties` is really distance from 0.5; renaming or inverting it would make intent clearer.\r\n\r\n# Results\r\n\r\nAfter a small amount of labeled data, the system:\r\n\r\n- classified **45,000+ images** automatically\r\n- required only **a few hundred** labeled examples\r\n- avoided weeks of manual effort\r\n- integrated cleanly with internal workflows\r\n- provided a reusable classification foundation\r\n\r\nThis wasn't a massive ML project - but it was extremely practical and rewarding. Classical ML works well here because CLIP embeddings are strong; the lift comes from the representation, not the model alone. Throughput gains (hours → minutes) were observed on my hardware with batched GPU inference; results will vary by GPU and disk speed.\r\n\r\n---\r\n\r\n# Lessons Learned\r\n\r\n- Zero-shot models make cold starts much easier\r\n- Classical ML is still highly effective\r\n- Data pipelines matter more than model size\r\n- Active learning dramatically cuts labeling work\r\n- Simple UIs can make or break adoption\r\n- Most ML engineering is systems engineering\r\n\r\nThis project reinforced skills I learned in college, my homelab, and at work - bringing them together in a real, applied setting.\r\n\r\n---\r\n\r\n# What's Next\r\n\r\nFuture improvements include:\r\n\r\n- Vendor upload portal with required metadata\r\n- Vector database (FAISS/Milvus) for similarity search\r\n- Expanded labels: renders, lifestyle, front/back packaging\r\n- Deploying as an internal microservice\r\n- Better UX for labeling\r\n- Feedback buttons on the B2B site\r\n\r\nEach step builds on a solid, working foundation.\r\n\r\n---\r\n\r\n# Conclusion\r\n\r\nThis project showed how small, well-scoped ML systems can bring real value without overengineering.\r\nBy combining zero-shot CLIP, classical ML, caching, and lightweight UIs, I was able to automate a large internal task efficiently.\r\n\r\nIt was a great learning experience and a chance to apply practical ML engineering concepts to real vendor data.\r\n\r\nIf you'd like to know more or are working on something similar, feel free to reach out - happy to share more details.\r\n",
    "contentHtml": "<h1>From Zero-Shot to Production: A Practical Image Classification Workflow</h1>\n<h2>Introduction</h2>\n<p>This project started with a simple internal question:</p>\n<p><strong>Can we automatically separate packaged vs. unpackaged product images in our catalog?</strong></p>\n<p>Vendors often send us ZIP files containing tens of thousands of mixed images - packaged shots, loose items, lifestyle photos, renders, and close-ups. There's no metadata, no naming structure, and no consistency.</p>\n<p>Manually sorting 45,000+ images wasn't realistic.\r\nInstead of treating this as a full \"ML initiative,\" I approached it the way I've tackled projects in my homelab or at school:</p>\n<ul>\n<li>start simple</li>\n<li>build only what's needed</li>\n<li>iterate as you learn</li>\n<li>keep the system practical</li>\n</ul>\n<p>That mindset led to a lightweight ML workflow that handled the entire dataset with only a few hundred human labels.</p>\n<hr>\n<h2>TLDR</h2>\n<p>I built a small internal ML system that uses:</p>\n<ul>\n<li><strong>Zero-shot OpenCLIP embeddings</strong> to start with no labels</li>\n<li><strong>A Logistic Regression classifier</strong> for fast supervised learning</li>\n<li><strong>Decision fusion:</strong> zero-shot + classifier + clustering</li>\n<li><strong>Embedding caching + batch GPU inference</strong> for efficiency</li>\n<li><strong>Active learning</strong> to reduce labeling effort</li>\n<li><strong>Two lightweight UIs</strong> (Qt + Flask) for quick labeling</li>\n</ul>\n<p>It wasn't a huge project - but it solved a real internal bottleneck and helped me sharpen applied ML engineering skills.</p>\n<hr>\n<h1>System Setup at a Glance</h1>\n<ul>\n<li><code>IMAGE_DIR=all_images</code>, outputs copied to <code>classified/packaged</code> and <code>classified/unpackaged</code></li>\n<li>Embeddings cached in <code>image_embeds_cache.pkl</code> with model/pretrained stamped to avoid stale reuse</li>\n<li>Labels stored in <code>labeled_images.pkl</code>, classifier in <code>trained_classifier.pkl</code></li>\n<li>Adaptive batching: defaults to 16 on GPU, 8 on CPU to balance throughput and memory</li>\n<li>Confidence guardrails: <code>CONFIDENCE_MARGIN=1.10</code>, active-learning queue capped at 1,000 per session</li>\n<li>Runs on CUDA if available, otherwise CPU; web UI via Flask, desktop UI via PySide6 Qt</li>\n</ul>\n<hr>\n<h1>Step 1: Starting With Zero-Shot CLIP</h1>\n<p>Because we had <em>zero</em> labeled images, I began with <strong>OpenCLIP ViT-H-14</strong>.</p>\n<p>I created simple text prompts to anchor packaged vs. unpackaged semantics:</p>\n<pre><code class=\"language-python\">packaged_prompts = [\r\n    \"a product in packaging\",\r\n    \"a boxed product\",\r\n    \"retail packaging\",\r\n]\r\n\r\nunpackaged_prompts = [\r\n    \"a product without packaging\",\r\n    \"product only, no box\",\r\n    \"item removed from packaging\",\r\n]\n</code></pre>\n<p>CLIP converts these into text embeddings:</p>\n<pre><code class=\"language-python\">with torch.no_grad():\r\n    text_tokens = tokenizer(all_prompts).to(device)\r\n    text_features = model.encode_text(text_tokens)\r\n    text_features /= text_features.norm(dim=-1, keepdim=True)\n</code></pre>\n<p>At this stage, zero-shot predictions were rough but surprisingly useful.\r\nThey formed the starting point for active learning and gave the first signal for classification (the zero-shot step is text–image similarity; the Logistic Regression later uses the image embeddings, not a “zero-shot embedding”).</p>\n<p>Implementation notes:</p>\n<ul>\n<li>Model: <code>open_clip.create_model_and_transforms(\"ViT-H-14\", \"laion2b_s32b_b79k\")</code></li>\n<li>Tokenization and encoding happen once at startup; embeddings are L2-normalized for clean cosine sims</li>\n<li>Runs in half precision on GPU for speed; AMP autocast mainly benefits GPU paths (it does not speed up CPU)</li>\n<li>CLIP packaging semantics are prompt-sensitive; packaging vs. unpackaged is not a native class, so prompts need tuning and still fluctuate</li>\n</ul>\n<p><img src=\"/images/zero-shot-to-production-image-classification/clip_architecture_sketch.png\" alt=\"CLIP architecture sketch showing dual encoders\">\n<em>Source: Pinecone guide to multi-modal ML with CLIP.</em></p>\n<p><img src=\"/images/zero-shot-to-production-image-classification/clip_pipeline_combined.png\" alt=\"CLIP contrastive pretraining and zero-shot pipeline\">\n<em>Source: LearnOpenCV CLIP tutorial.</em></p>\n<hr>\n<h1>Step 2: Adding a Lightweight Supervised Layer</h1>\n<p>Once I labeled a small set of examples, I trained a <strong>Logistic Regression classifier</strong> on the CLIP embeddings:</p>\n<pre><code class=\"language-python\">clf = LogisticRegression(max_iter=2000)\r\nclf.fit(X_train, y_train)\n</code></pre>\n<p>This was intentional:</p>\n<ul>\n<li>it trains fast</li>\n<li>it works well on small datasets</li>\n<li>it updates instantly</li>\n<li>no GPU required</li>\n</ul>\n<p>It quickly began outperforming zero-shot predictions, even with &#x3C;200 labeled samples. The probabilities are not calibrated (especially with few labels), so they are best treated as relative scores, not ground-truth confidence.</p>\n<p>Persistence and guardrails:</p>\n<ul>\n<li>Labels are saved to <code>labeled_images.pkl</code>; classifier is persisted to <code>trained_classifier.pkl</code></li>\n<li>Training only kicks in after at least 10 samples with both classes represented</li>\n<li>The Qt and web labelers retrain every 10 labels so the model keeps getting sharper during a session</li>\n</ul>\n<p><img src=\"/images/zero-shot-to-production-image-classification/logistic_curve.png\" alt=\"Logistic sigmoid curve\">\n<em>Source: Wikimedia Commons (“Logistic-curve.svg”).</em></p>\n<hr>\n<h1>Step 3: Decision Fusion</h1>\n<p>Vendor data is extremely inconsistent. Images vary in lighting, angle, background, and composition.</p>\n<p>To stabilize predictions, I combined three signals:</p>\n<ol>\n<li><strong>Zero-shot confidence</strong></li>\n<li><strong>Classifier probability</strong></li>\n<li><strong>KMeans cluster prior</strong></li>\n</ol>\n<p>The fusion logic looked like this:</p>\n<pre><code class=\"language-python\">if clf is not None:\r\n    prob_packaged = clf.predict_proba(feat.reshape(1, -1))[0, 1]\r\n    return \"packaged\" if prob_packaged >= 0.5 else \"unpackaged\"\r\n\r\nzs_label, sims = zero_shot_label(feat)\r\ncluster = cluster_labels[idx]\r\n\r\n# fallback heuristics\r\nif zs_packaged and cluster_is_packaged:\r\n    return \"packaged\"\r\nif (not zs_packaged) and (not cluster_is_packaged):\r\n    return \"unpackaged\"\n</code></pre>\n<p>This was a simple but effective way to resolve ambiguity and smooth out noisy cases.</p>\n<p>Details:</p>\n<ul>\n<li>KMeans (k=2) runs over all embeddings once per session; the cluster with higher similarity to packaged prompts becomes the packaged prior</li>\n<li>When a trained classifier exists, it currently takes precedence; otherwise fusion falls back to zero-shot + clusters with a small confidence margin (<code>1.10</code> multiplies the stronger signal before accepting it)</li>\n<li>True fusion is not implemented yet; blending all signals when LR is near 0.5 would be more robust than hard precedence</li>\n</ul>\n<p><img src=\"/images/zero-shot-to-production-image-classification/kmeans_convergence.png\" alt=\"KMeans convergence illustration\">\n<em>Source: Wikipedia K-means clustering article (convergence example).</em></p>\n<hr>\n<h1>Step 4: Scaling With Embedding Caching &#x26; Batch Inference</h1>\n<p>Computing embeddings for 45k images is expensive.\r\nRecomputing them every run would have been painful.</p>\n<p>So I built a persistent caching layer:</p>\n<pre><code class=\"language-python\">if os.path.exists(EMBED_CACHE_PATH):\r\n    cache = pickle.load(f)\r\n    embeds = cache.get(\"embeds\", {})\n</code></pre>\n<p>It detects:</p>\n<ul>\n<li>images missing from cache</li>\n<li>stale entries where the file was deleted</li>\n<li>model changes that require invalidation</li>\n</ul>\n<p>When embedding new images, I switched to <strong>batched GPU inference</strong>:</p>\n<pre><code class=\"language-python\">with torch.no_grad(), torch.cuda.amp.autocast():\r\n    feats = model.encode_image(batch_tensor)\r\n    feats /= feats.norm(dim=-1, keepdim=True)\n</code></pre>\n<p>This alone sped up processing from hours to minutes.</p>\n<p>The embedding manager also:</p>\n<ul>\n<li>Detects missing/stale files and prompts whether to embed only missing files or re-embed everything</li>\n<li>Logs throughput and saves file order alongside embeddings so downstream steps stay aligned</li>\n<li>Uses batched tensor stacks to keep the GPU/CPU busy instead of looping image-by-image</li>\n<li>Model stamping avoids stale reuse across model changes, but it does not hash images; if files change without renaming, a hash/mtime check would be required for full staleness detection</li>\n</ul>\n<hr>\n<h1>Step 5: Active Learning to Reduce Labeling</h1>\n<p>Labeling is the real bottleneck.\nTo minimize the amount of manual labeling, I ranked images by <strong>uncertainty</strong>:</p>\n<pre><code class=\"language-python\">uncertainties = np.abs(probs[:, 1] - 0.5)\r\nidxs = np.argsort(uncertainties)\n</code></pre>\n<p>Images closest to 0.5 probability are the most valuable to label.</p>\n<p>Every 10 labels, the classifier retrained:</p>\n<pre><code class=\"language-python\">if len(label_db) % 10 == 0:\r\n    clf = train_classifier_from_labels(embeds, label_db)\n</code></pre>\n<p>This feedback loop dramatically reduced labeling effort.\r\nA few hundred labels were enough for strong performance across all 45k images.</p>\n<p>How the queue is built:</p>\n<ul>\n<li>Keeps a session-scoped queue up to 1,000 items</li>\n<li>If a classifier exists, it sorts by uncertainty (closest to 0.5) so every label delivers maximum lift (the variable is named <code>uncertainties</code>, but it is really a distance-from-0.5 score; smaller means more uncertain—the naming is inverted)</li>\n<li>Falls back to random sampling when no classifier is available yet</li>\n<li>Global stats (confidence rate, packaged ratio, average margin) are computed upfront to give labeling context</li>\n</ul>\n<p><img src=\"/images/zero-shot-to-production-image-classification/active_learning_diagram.png\" alt=\"Active learning loop diagram\">\n<em>Source: Neptune AI (diagram of active learning system).</em></p>\n<hr>\n<h1>Step 6: Building Helpful Labeling Tools</h1>\n<p>Two simple UIs made the workflow much more usable:</p>\n<h2>Qt Desktop App</h2>\n<pre><code class=\"language-python\">self.info_label.setText(\r\n    f\"{fname}\\nPrediction: {pred} ({prob*100:.1f}%)\\nZero-shot: {zs_prob*100:.1f}%\"\r\n)\n</code></pre>\n<p>Fast, responsive, and keyboard-friendly.</p>\n<h2>Flask Web Dashboard</h2>\n<pre><code class=\"language-python\">@app.route(\"/label\", methods=[\"POST\"])\r\ndef label():\r\n    label_db[fname] = request.form.get(\"label\")\r\n    save_label_db(label_db)\n</code></pre>\n<p>Accessible to anyone without installation.</p>\n<p>This made labeling collaborative and painless.</p>\n<p>Quality-of-life touches:</p>\n<ul>\n<li>Qt UI shows prediction, zero-shot confidence, packaged ratio, and dataset-level stats; retrains every 10 labels</li>\n<li>Web UI serves images directly from disk (<code>/_img/&#x3C;filename></code>) and retrains periodically without restarting the server</li>\n</ul>\n<hr>\n<h1>Batch Classification Path</h1>\n<p>When labeling is done (or when you just want a quick pass), batch mode runs end-to-end:</p>\n<ol>\n<li>Load or build embeddings (reusing cache)</li>\n<li>Load labels and classifier; retrain if new labels are present</li>\n<li>Run KMeans for cluster priors</li>\n<li>Decide packaged/unpackaged for every file using classifier-first, then zero-shot + clusters</li>\n<li>Copy images into <code>classified/packaged</code> and <code>classified/unpackaged</code></li>\n</ol>\n<hr>\n<h1>Caveats and Future Fixes</h1>\n<ul>\n<li>True fusion: the current logic lets the Logistic Regression call the shot even at 0.501 probability; a better approach would down-weight LR when it is near 0.5 and lean on zero-shot + clusters in that band.</li>\n<li>Cluster prior: the k=2 KMeans prior is unvalidated; if clusters track background color instead of packaging, it can hurt accuracy. A simple guard would be to check cluster-packaged alignment against a labeled sample before using it.</li>\n<li>Naming clarity: the active-learning score called <code>uncertainties</code> is really distance from 0.5; renaming or inverting it would make intent clearer.</li>\n</ul>\n<h1>Results</h1>\n<p>After a small amount of labeled data, the system:</p>\n<ul>\n<li>classified <strong>45,000+ images</strong> automatically</li>\n<li>required only <strong>a few hundred</strong> labeled examples</li>\n<li>avoided weeks of manual effort</li>\n<li>integrated cleanly with internal workflows</li>\n<li>provided a reusable classification foundation</li>\n</ul>\n<p>This wasn't a massive ML project - but it was extremely practical and rewarding. Classical ML works well here because CLIP embeddings are strong; the lift comes from the representation, not the model alone. Throughput gains (hours → minutes) were observed on my hardware with batched GPU inference; results will vary by GPU and disk speed.</p>\n<hr>\n<h1>Lessons Learned</h1>\n<ul>\n<li>Zero-shot models make cold starts much easier</li>\n<li>Classical ML is still highly effective</li>\n<li>Data pipelines matter more than model size</li>\n<li>Active learning dramatically cuts labeling work</li>\n<li>Simple UIs can make or break adoption</li>\n<li>Most ML engineering is systems engineering</li>\n</ul>\n<p>This project reinforced skills I learned in college, my homelab, and at work - bringing them together in a real, applied setting.</p>\n<hr>\n<h1>What's Next</h1>\n<p>Future improvements include:</p>\n<ul>\n<li>Vendor upload portal with required metadata</li>\n<li>Vector database (FAISS/Milvus) for similarity search</li>\n<li>Expanded labels: renders, lifestyle, front/back packaging</li>\n<li>Deploying as an internal microservice</li>\n<li>Better UX for labeling</li>\n<li>Feedback buttons on the B2B site</li>\n</ul>\n<p>Each step builds on a solid, working foundation.</p>\n<hr>\n<h1>Conclusion</h1>\n<p>This project showed how small, well-scoped ML systems can bring real value without overengineering.\r\nBy combining zero-shot CLIP, classical ML, caching, and lightweight UIs, I was able to automate a large internal task efficiently.</p>\n<p>It was a great learning experience and a chance to apply practical ML engineering concepts to real vendor data.</p>\n<p>If you'd like to know more or are working on something similar, feel free to reach out - happy to share more details.</p>\n",
    "author": "Aayush Pathak",
    "date": "2025-09-04",
    "readTime": 7,
    "category": "Case Study",
    "tags": [
      "Machine Learning",
      "Computer Vision",
      "Active Learning",
      "ML Engineering",
      "Zero-Shot Models"
    ],
    "image": "/images/zero-shot-to-production-image-classification/main.png",
    "featured": true
  },
  {
    "slug": "introducing-justdev-tools",
    "title": "Introducing justdev.tools",
    "excerpt": "A privacy-first, installable PWA with fast, local developer utilities. Works offline. No accounts. No data leaves your device.",
    "content": "\r\n# justdev.tools\r\n\r\n## Introduction\r\n\r\nI built **justdev.tools** to remove friction from everyday developer work. it is a **progressive web app** that installs directly from your browser, runs offline after the first visit, and keeps every operation on your device. there are no accounts and no servers in the path of your data. it is fast, simple, and dependable.\r\n\r\n## why this exists\r\n\r\nmost days, you need quick utilities while context switching across tasks. format a payload, decode a token, resize an image, generate a hash, preview a QR, convert text encodings, clean CSVs, validate a regex, or create sample data. jumping between random sites wastes time and raises privacy concerns. I wanted a single place that opens instantly, works on desktop and mobile, and respects your data.\r\n\r\n## what you can do (high level)\r\n\r\n- convert and transform data: json, yaml, xml, csv, url encode/decode, base64, hex\r\n- generate and verify: uuids, hashes, checksums, lorem, timestamps, slugs\r\n- security helpers: view headers, decode tokens, inspect payloads, redaction aids\r\n- text and content helpers: diff, prettify, minify, case transforms\r\n- media helpers: basic image resize and optimize, quick qr/barcode generation\r\n- testing helpers: regex tester, http payload builder, time and date utilities\r\n\r\nevery operation runs locally in the browser. nothing is uploaded.\r\n\r\n## privacy and performance\r\n\r\nprivacy was the first constraint. all tools operate in memory on the client side. there is no analytics that fingerprints you and no telemetry that exfiltrates your inputs. performance was the second constraint. the app is pre-cached, so once you open it, it launches instantly and continues to work even when you are offline.\r\n\r\n## install it as an app\r\n\r\n**desktop (chrome, edge, brave):**\r\nopen justdev.tools, look for the “install” or “open as app” icon in the address bar, then confirm.\r\n\r\n**android (chrome):**\r\nopen justdev.tools, tap the browser menu, choose “add to home screen,” then confirm.\r\n\r\n**ios (safari):**\r\nopen justdev.tools, tap the share icon, choose “add to home screen,” then confirm.\r\n\r\nafter install, it behaves like a native app with its own icon and window.\r\n\r\n## keyboard and workflow notes\r\n\r\n- every tool favors keyboard input and instant feedback\r\n- common actions use familiar shortcuts where possible\r\n- state is kept minimal and local so you can paste, transform, and move on\r\n\r\n## roadmap\r\n\r\n- more offline-capable utilities based on your requests\r\n- deeper text, data, and media helpers where local processing makes sense\r\n- small quality-of-life improvements that keep the app lightweight\r\n\r\n## how to give feedback\r\n\r\nif there is a utility you reach for often and want it inside justdev.tools, send it my way. the goal is a trustworthy toolbox that saves seconds many times a day without asking for anything in return.\r\n\r\n**open the app:** https://justdev.tools\r\n",
    "contentHtml": "<h1>justdev.tools</h1>\n<h2>Introduction</h2>\n<p>I built <strong>justdev.tools</strong> to remove friction from everyday developer work. it is a <strong>progressive web app</strong> that installs directly from your browser, runs offline after the first visit, and keeps every operation on your device. there are no accounts and no servers in the path of your data. it is fast, simple, and dependable.</p>\n<h2>why this exists</h2>\n<p>most days, you need quick utilities while context switching across tasks. format a payload, decode a token, resize an image, generate a hash, preview a QR, convert text encodings, clean CSVs, validate a regex, or create sample data. jumping between random sites wastes time and raises privacy concerns. I wanted a single place that opens instantly, works on desktop and mobile, and respects your data.</p>\n<h2>what you can do (high level)</h2>\n<ul>\n<li>convert and transform data: json, yaml, xml, csv, url encode/decode, base64, hex</li>\n<li>generate and verify: uuids, hashes, checksums, lorem, timestamps, slugs</li>\n<li>security helpers: view headers, decode tokens, inspect payloads, redaction aids</li>\n<li>text and content helpers: diff, prettify, minify, case transforms</li>\n<li>media helpers: basic image resize and optimize, quick qr/barcode generation</li>\n<li>testing helpers: regex tester, http payload builder, time and date utilities</li>\n</ul>\n<p>every operation runs locally in the browser. nothing is uploaded.</p>\n<h2>privacy and performance</h2>\n<p>privacy was the first constraint. all tools operate in memory on the client side. there is no analytics that fingerprints you and no telemetry that exfiltrates your inputs. performance was the second constraint. the app is pre-cached, so once you open it, it launches instantly and continues to work even when you are offline.</p>\n<h2>install it as an app</h2>\n<p><strong>desktop (chrome, edge, brave):</strong>\r\nopen justdev.tools, look for the “install” or “open as app” icon in the address bar, then confirm.</p>\n<p><strong>android (chrome):</strong>\r\nopen justdev.tools, tap the browser menu, choose “add to home screen,” then confirm.</p>\n<p><strong>ios (safari):</strong>\r\nopen justdev.tools, tap the share icon, choose “add to home screen,” then confirm.</p>\n<p>after install, it behaves like a native app with its own icon and window.</p>\n<h2>keyboard and workflow notes</h2>\n<ul>\n<li>every tool favors keyboard input and instant feedback</li>\n<li>common actions use familiar shortcuts where possible</li>\n<li>state is kept minimal and local so you can paste, transform, and move on</li>\n</ul>\n<h2>roadmap</h2>\n<ul>\n<li>more offline-capable utilities based on your requests</li>\n<li>deeper text, data, and media helpers where local processing makes sense</li>\n<li>small quality-of-life improvements that keep the app lightweight</li>\n</ul>\n<h2>how to give feedback</h2>\n<p>if there is a utility you reach for often and want it inside justdev.tools, send it my way. the goal is a trustworthy toolbox that saves seconds many times a day without asking for anything in return.</p>\n<p><strong>open the app:</strong> https://justdev.tools</p>\n",
    "author": "Aayush Pathak",
    "date": "2025-09-04",
    "readTime": 4,
    "category": "Product",
    "tags": [
      "PWA",
      "Developer Tools",
      "WebDev",
      "Privacy",
      "Offline",
      "Productivity"
    ],
    "image": "images/justdev/justdev.png",
    "featured": true
  },
  {
    "slug": "from-homelab-to-production-devops-foundation",
    "title": "From Homelab to Production: How I Built an On-Prem DevOps & IT Foundation",
    "excerpt": "A deep dive into how I transformed Kidcentral Supply’s IT and DevOps environment using lessons from my homelab.",
    "content": "\r\n# From Homelab to Production: How I Built an On-Prem DevOps & IT Foundation\r\n\r\n## Introduction\r\n\r\nWhen I joined Kidcentral Supply as an intern in 2023, the IT setup was lean and heavily outsourced. Most systems were SaaS subscriptions, development work was handled by vendors, and the internal IT team’s role was mainly about supporting the ERP and running queries when managers needed data.\r\n\r\nFor a company that isn’t primarily a software business, this made sense. IT spend wasn’t tied directly to revenue, so the thinking was simple: why build when you can buy?\r\n\r\nBut my background was different. I had spent years tinkering in my homelab — setting up servers, breaking and fixing virtual machines, experimenting with different ways of automating tasks, containerizing services, and figuring out how to monitor them. That experience wasn’t theoretical. It was practical training.\r\n\r\nThe real question was: could I bring those lessons into a production environment?\r\n\r\n---\r\n\r\n## TLDR\r\n\r\nI started by proving that ERP data could be securely extracted and used for internal tools. That proof of concept led to approval for a modest on-prem server. I set up virtualization, a proxy layer, and a foundation for internal services.\r\n\r\nOver time, I layered in containerized deployments, automated scheduling, external monitoring, and incident management integrated into existing team tools. I built services that powered secure dashboards with live operational insights.\r\n\r\nFinally, I replaced costly outsourced integrations with an internal system that could be deployed in minutes.\r\n\r\nThe results: cost savings, faster deployments, live dashboards for managers, and a cultural shift from “buy first” to “try to build first.”\r\n\r\n---\r\n\r\n![A high-level overview of the homelab infrastructure.](/images/Kidcentral_DevOps/kidcentral_visual1.png)\r\n\r\n## Step 1: Proof of Concept\r\n\r\nThe first breakthrough was showing that ERP data could be securely tapped and used to build custom tools. Instead of being limited by what the ERP offered, we could extend it.\r\n\r\nI built a simple proof of concept that turned raw database queries into a small internal tool with real business utility. That demo showed leadership we weren’t talking theory — we were talking immediate value.\r\n\r\nIt was enough to justify investing in a modest server for on-prem experiments. That small step changed everything.\r\n\r\n---\r\n\r\n![An example image description](/images/Kidcentral_DevOps/kidcentral_visual2.png)\r\n\r\n## Step 2: Standing Up Infrastructure\r\n\r\nThe new server became the foundation. I installed a hypervisor to run multiple isolated services side by side. Virtual machines let me separate workloads while still running on one piece of hardware.\r\n\r\nOn top of that, I set up a proxy layer. This handled routing requests, securing connections, and making sure multiple apps could live behind a single public entry point. With this in place, the infrastructure could grow without constantly needing new IPs or DNS changes.\r\n\r\nIt wasn’t huge. But it was stable, expandable, and ours.\r\n\r\n---\r\n\r\n![An example image description](/images/Kidcentral_DevOps/kidcentral_visual3.png)\r\n\r\n## Step 3: Deployments and Automation\r\n\r\nAt first, applications were simple services running directly on the server. That worked, but it wasn’t flexible. So I began containerizing apps, making them portable and easier to manage.\r\n\r\nAs the environment grew, I added a lightweight management layer that made it possible to spin up new services or redeploy existing ones in minutes. No more waiting on external vendors for every change.\r\n\r\nAutomation was another layer. Scheduled jobs handled recurring tasks, while event-driven triggers responded to real-world signals like incoming orders or updated data. The system went from manual to largely self-sufficient.\r\n\r\n---\r\n\r\n## Step 4: Monitoring and Incident Management\r\n\r\nReliability became the next challenge. If infrastructure is invisible when it works, it’s painfully visible when it fails.\r\n\r\nI set up external monitoring so that even if our internal systems were offline, the status page stayed up. This gave leadership visibility and gave IT a way to show transparency.\r\n\r\nI also tied incident reporting directly into the tools the team already used every day. If something broke, they didn’t need to learn a new incident system — they could report, update, and close issues from inside their normal workflow. That cut response times dramatically diminished and reduced friction.\r\n\r\n---\r\n\r\n## Step 5: Custom Apps and Integrations\r\n\r\nWith the base infrastructure in place, I built internal services that exposed ERP and operational data securely. These powered a company-wide dashboard that anyone with the right permissions could use.\r\n\r\nInstead of waiting hours or days for someone to pull data and email it, managers could open a dashboard and see live targets, sales, and projections instantly. Access was restricted with domain accounts and role-based permissions, so data stayed protected.\r\n\r\nThe next step was integrations. Previously, e-commerce to ERP integrations were outsourced. They cost tens of thousands of dollars and took months to deliver. I built a reusable internal system where new integrations could be deployed in minutes. This eliminated massive vendor costs and gave us full control.\r\n\r\n---\r\n\r\n## Results\r\n\r\nCost savings were immediate. We cut recurring contracts, transaction fees, and vendor support retainers.\r\n\r\nDeployment times dropped from months to days, sometimes hours.\r\n\r\nSupport times went from six hours to minutes. My record production fix took thirty seconds.\r\n\r\nManagers had real-time dashboards instead of emailed SQL reports.\r\n\r\nAnd the culture shifted. The default wasn’t “what do we buy,” it was “can we build this ourselves?”\r\n\r\n---\r\n\r\n## Lessons Learned\r\n\r\nSmall proofs of concept can change everything.\r\n\r\nExperiments in a homelab directly translate to production when you apply them with discipline.\r\n\r\nReal-time dashboards don’t just save time — they change how leaders make decisions.\r\n\r\nTemplates and repeatability are the real foundation of speed.\r\n\r\nPeople adopt tools faster when those tools live inside apps they already use.\r\n\r\n---\r\n\r\n## What’s Next\r\n\r\nThe foundation is solid, but there’s more to do.\r\n\r\nFuture improvements include moving to Git-driven deployment pipelines with artifact verification, expanding observability with metrics and tracing, and centralizing secret management. Some scheduled jobs should graduate to an orchestrator for reliability.\r\n\r\nI also want to run failure drills so recovery times are predictable, not just fast. And eventually, we’ll look at progressive deployment strategies for critical services to further reduce risk.\r\n\r\n---\r\n\r\n## Conclusion\r\n\r\nThis project proved something important. Innovation doesn’t always come from big budgets or big vendors. It comes from curiosity, persistence, and the willingness to turn small experiments into production systems.\r\n\r\nAt Kidcentral Supply, homelab lessons became real-world impact. Costs went down, speed went up, and data became instantly available. The company became more resilient and more self-reliant.\r\n\r\nIf you’re at a small or mid-sized business wondering whether it’s worth building internally, the answer is yes. Start small. Prove value. Scale step by step.\r\n\r\nAnd if you’re curious about the details of how I did it, reach out. I’d be happy to share more.\r\n",
    "contentHtml": "<h1>From Homelab to Production: How I Built an On-Prem DevOps &#x26; IT Foundation</h1>\n<h2>Introduction</h2>\n<p>When I joined Kidcentral Supply as an intern in 2023, the IT setup was lean and heavily outsourced. Most systems were SaaS subscriptions, development work was handled by vendors, and the internal IT team’s role was mainly about supporting the ERP and running queries when managers needed data.</p>\n<p>For a company that isn’t primarily a software business, this made sense. IT spend wasn’t tied directly to revenue, so the thinking was simple: why build when you can buy?</p>\n<p>But my background was different. I had spent years tinkering in my homelab — setting up servers, breaking and fixing virtual machines, experimenting with different ways of automating tasks, containerizing services, and figuring out how to monitor them. That experience wasn’t theoretical. It was practical training.</p>\n<p>The real question was: could I bring those lessons into a production environment?</p>\n<hr>\n<h2>TLDR</h2>\n<p>I started by proving that ERP data could be securely extracted and used for internal tools. That proof of concept led to approval for a modest on-prem server. I set up virtualization, a proxy layer, and a foundation for internal services.</p>\n<p>Over time, I layered in containerized deployments, automated scheduling, external monitoring, and incident management integrated into existing team tools. I built services that powered secure dashboards with live operational insights.</p>\n<p>Finally, I replaced costly outsourced integrations with an internal system that could be deployed in minutes.</p>\n<p>The results: cost savings, faster deployments, live dashboards for managers, and a cultural shift from “buy first” to “try to build first.”</p>\n<hr>\n<p><img src=\"/images/Kidcentral_DevOps/kidcentral_visual1.png\" alt=\"A high-level overview of the homelab infrastructure.\"></p>\n<h2>Step 1: Proof of Concept</h2>\n<p>The first breakthrough was showing that ERP data could be securely tapped and used to build custom tools. Instead of being limited by what the ERP offered, we could extend it.</p>\n<p>I built a simple proof of concept that turned raw database queries into a small internal tool with real business utility. That demo showed leadership we weren’t talking theory — we were talking immediate value.</p>\n<p>It was enough to justify investing in a modest server for on-prem experiments. That small step changed everything.</p>\n<hr>\n<p><img src=\"/images/Kidcentral_DevOps/kidcentral_visual2.png\" alt=\"An example image description\"></p>\n<h2>Step 2: Standing Up Infrastructure</h2>\n<p>The new server became the foundation. I installed a hypervisor to run multiple isolated services side by side. Virtual machines let me separate workloads while still running on one piece of hardware.</p>\n<p>On top of that, I set up a proxy layer. This handled routing requests, securing connections, and making sure multiple apps could live behind a single public entry point. With this in place, the infrastructure could grow without constantly needing new IPs or DNS changes.</p>\n<p>It wasn’t huge. But it was stable, expandable, and ours.</p>\n<hr>\n<p><img src=\"/images/Kidcentral_DevOps/kidcentral_visual3.png\" alt=\"An example image description\"></p>\n<h2>Step 3: Deployments and Automation</h2>\n<p>At first, applications were simple services running directly on the server. That worked, but it wasn’t flexible. So I began containerizing apps, making them portable and easier to manage.</p>\n<p>As the environment grew, I added a lightweight management layer that made it possible to spin up new services or redeploy existing ones in minutes. No more waiting on external vendors for every change.</p>\n<p>Automation was another layer. Scheduled jobs handled recurring tasks, while event-driven triggers responded to real-world signals like incoming orders or updated data. The system went from manual to largely self-sufficient.</p>\n<hr>\n<h2>Step 4: Monitoring and Incident Management</h2>\n<p>Reliability became the next challenge. If infrastructure is invisible when it works, it’s painfully visible when it fails.</p>\n<p>I set up external monitoring so that even if our internal systems were offline, the status page stayed up. This gave leadership visibility and gave IT a way to show transparency.</p>\n<p>I also tied incident reporting directly into the tools the team already used every day. If something broke, they didn’t need to learn a new incident system — they could report, update, and close issues from inside their normal workflow. That cut response times dramatically diminished and reduced friction.</p>\n<hr>\n<h2>Step 5: Custom Apps and Integrations</h2>\n<p>With the base infrastructure in place, I built internal services that exposed ERP and operational data securely. These powered a company-wide dashboard that anyone with the right permissions could use.</p>\n<p>Instead of waiting hours or days for someone to pull data and email it, managers could open a dashboard and see live targets, sales, and projections instantly. Access was restricted with domain accounts and role-based permissions, so data stayed protected.</p>\n<p>The next step was integrations. Previously, e-commerce to ERP integrations were outsourced. They cost tens of thousands of dollars and took months to deliver. I built a reusable internal system where new integrations could be deployed in minutes. This eliminated massive vendor costs and gave us full control.</p>\n<hr>\n<h2>Results</h2>\n<p>Cost savings were immediate. We cut recurring contracts, transaction fees, and vendor support retainers.</p>\n<p>Deployment times dropped from months to days, sometimes hours.</p>\n<p>Support times went from six hours to minutes. My record production fix took thirty seconds.</p>\n<p>Managers had real-time dashboards instead of emailed SQL reports.</p>\n<p>And the culture shifted. The default wasn’t “what do we buy,” it was “can we build this ourselves?”</p>\n<hr>\n<h2>Lessons Learned</h2>\n<p>Small proofs of concept can change everything.</p>\n<p>Experiments in a homelab directly translate to production when you apply them with discipline.</p>\n<p>Real-time dashboards don’t just save time — they change how leaders make decisions.</p>\n<p>Templates and repeatability are the real foundation of speed.</p>\n<p>People adopt tools faster when those tools live inside apps they already use.</p>\n<hr>\n<h2>What’s Next</h2>\n<p>The foundation is solid, but there’s more to do.</p>\n<p>Future improvements include moving to Git-driven deployment pipelines with artifact verification, expanding observability with metrics and tracing, and centralizing secret management. Some scheduled jobs should graduate to an orchestrator for reliability.</p>\n<p>I also want to run failure drills so recovery times are predictable, not just fast. And eventually, we’ll look at progressive deployment strategies for critical services to further reduce risk.</p>\n<hr>\n<h2>Conclusion</h2>\n<p>This project proved something important. Innovation doesn’t always come from big budgets or big vendors. It comes from curiosity, persistence, and the willingness to turn small experiments into production systems.</p>\n<p>At Kidcentral Supply, homelab lessons became real-world impact. Costs went down, speed went up, and data became instantly available. The company became more resilient and more self-reliant.</p>\n<p>If you’re at a small or mid-sized business wondering whether it’s worth building internally, the answer is yes. Start small. Prove value. Scale step by step.</p>\n<p>And if you’re curious about the details of how I did it, reach out. I’d be happy to share more.</p>\n",
    "author": "Aayush Pathak",
    "date": "2025-09-04",
    "readTime": 6,
    "category": "Case Study",
    "tags": [
      "DevOps",
      "Infrastructure",
      "Automation",
      "Digital Transformation",
      "On-Prem"
    ],
    "image": "/images/Kidcentral_DevOps/blog-cover.png",
    "featured": true
  }
];

export const projects: ProjectPost[] = [
  {
    "slug": "beyondcalories-ca",
    "title": "BeyondCalories.ca",
    "excerpt": "A hackathon project that built a recipe recommendation platform using an inverted graph over half a million recipes, providing real‑time search and AI‑powered suggestions based on pantry ingredients and user criteria.",
    "content": "\r\n# BeyondCalories.ca\r\n\r\nBeyondCalories.ca was built during a hackathon to explore how artificial intelligence and modern search technologies can help users find the perfect recipe. The platform indexed roughly 500 k recipes and stored their relationships in an inverted graph so that queries on pantry ingredients and preferences could return relevant suggestions. The architecture consisted of:\r\n\r\n- **Real‑time search** – Elasticsearch powered instantaneous querying over the large recipe corpus, enabling faceted filtering and full‑text search.\r\n- **AI recommendations** – algorithms interpreted pantry contents and user dietary criteria to recommend healthy, interesting meals.\r\n- **FastAPI backend** – a Python‑based API served search and recommendation requests, exposing endpoints consumed by a React frontend.\r\n- **Responsive UI** – the React client provided a smooth user experience and dynamic filters.\r\n\r\nThis hackathon project demonstrates how search and machine learning can enhance everyday cooking by turning random ingredients into delicious meals.\r\n",
    "contentHtml": "<h1>BeyondCalories.ca</h1>\n<p>BeyondCalories.ca was built during a hackathon to explore how artificial intelligence and modern search technologies can help users find the perfect recipe. The platform indexed roughly 500 k recipes and stored their relationships in an inverted graph so that queries on pantry ingredients and preferences could return relevant suggestions. The architecture consisted of:</p>\n<ul>\n<li><strong>Real‑time search</strong> – Elasticsearch powered instantaneous querying over the large recipe corpus, enabling faceted filtering and full‑text search.</li>\n<li><strong>AI recommendations</strong> – algorithms interpreted pantry contents and user dietary criteria to recommend healthy, interesting meals.</li>\n<li><strong>FastAPI backend</strong> – a Python‑based API served search and recommendation requests, exposing endpoints consumed by a React frontend.</li>\n<li><strong>Responsive UI</strong> – the React client provided a smooth user experience and dynamic filters.</li>\n</ul>\n<p>This hackathon project demonstrates how search and machine learning can enhance everyday cooking by turning random ingredients into delicious meals.</p>\n",
    "image": "/images/beyond-calories.png",
    "technologies": [
      "AI",
      "Elasticsearch",
      "FastAPI",
      "React"
    ],
    "githubUrl": "",
    "liveUrl": "https://beyondcalories.ca",
    "date": "2025-09-13",
    "category": "Software Development",
    "featured": true
  },
  {
    "slug": "justdev-tools",
    "title": "JustDev.tools",
    "excerpt": "A privacy‑first progressive web app that bundles dozens of developer utilities—conversions, hash generators, media tools, and more—into an installable offline toolbox.",
    "content": "\r\n# JustDev.tools\r\n\r\nJustDev.tools is a collection of lightweight, privacy‑first utilities designed to eliminate context switching during development. Built as an installable progressive web app, it runs entirely in your browser and continues to work offline after the first visit. There are no accounts, no servers and no data leaves your device, making it both fast and dependable. The toolbox exists because developers frequently need to format payloads, decode tokens, generate hashes or test regular expressions without leaving their current task.\r\n\r\n## Features\r\n\r\n- **Data conversion** – convert between JSON, YAML, XML, CSV and perform URL encoding/decoding and base64/hex transforms.\r\n- **Generation & verification** – create UUIDs, hashes, checksums, lorem ipsum text, timestamps and slugs.\r\n- **Security helpers** – decode JWT tokens, inspect HTTP headers and redact sensitive payloads.\r\n- **Content tools** – diff, prettify or minify text; change case; and clean CSVs.\r\n- **Media & testing** – resize images, generate QR/barcodes, test regex patterns, build HTTP requests and perform time/date calculations.\r\n\r\n## Privacy and Performance\r\n\r\nAll operations are executed in memory on the client; nothing is uploaded and there is no analytics. The app is pre‑cached so it launches instantly and works offline, providing a native‑like experience when installed on desktop or mobile. It favors keyboard shortcuts and maintains minimal state, allowing you to paste, transform and move on quickly.\r\n\r\nJustDev.tools demonstrates that productivity apps don’t need to compromise on privacy to be effective. It’s a trustworthy companion that saves seconds every day without asking for anything in return.\r\n",
    "contentHtml": "<h1>JustDev.tools</h1>\n<p>JustDev.tools is a collection of lightweight, privacy‑first utilities designed to eliminate context switching during development. Built as an installable progressive web app, it runs entirely in your browser and continues to work offline after the first visit. There are no accounts, no servers and no data leaves your device, making it both fast and dependable. The toolbox exists because developers frequently need to format payloads, decode tokens, generate hashes or test regular expressions without leaving their current task.</p>\n<h2>Features</h2>\n<ul>\n<li><strong>Data conversion</strong> – convert between JSON, YAML, XML, CSV and perform URL encoding/decoding and base64/hex transforms.</li>\n<li><strong>Generation &#x26; verification</strong> – create UUIDs, hashes, checksums, lorem ipsum text, timestamps and slugs.</li>\n<li><strong>Security helpers</strong> – decode JWT tokens, inspect HTTP headers and redact sensitive payloads.</li>\n<li><strong>Content tools</strong> – diff, prettify or minify text; change case; and clean CSVs.</li>\n<li><strong>Media &#x26; testing</strong> – resize images, generate QR/barcodes, test regex patterns, build HTTP requests and perform time/date calculations.</li>\n</ul>\n<h2>Privacy and Performance</h2>\n<p>All operations are executed in memory on the client; nothing is uploaded and there is no analytics. The app is pre‑cached so it launches instantly and works offline, providing a native‑like experience when installed on desktop or mobile. It favors keyboard shortcuts and maintains minimal state, allowing you to paste, transform and move on quickly.</p>\n<p>JustDev.tools demonstrates that productivity apps don’t need to compromise on privacy to be effective. It’s a trustworthy companion that saves seconds every day without asking for anything in return.</p>\n",
    "image": "/images/justdevtools.png",
    "technologies": [
      "PWA",
      "React",
      "Vite",
      "JavaScript"
    ],
    "githubUrl": "",
    "liveUrl": "https://justdev.tools",
    "date": "2025-09-04",
    "category": "Developer Tools",
    "featured": true
  },
  {
    "slug": "saas-accounting-invoicing-platform",
    "title": "SaaS Accounting & Invoicing Platform",
    "excerpt": "A modern small‑business finance platform built on Next.js and Postgres, delivering fast invoicing, clean ledger workflows and pragmatic CI/CD and observability practices.",
    "content": "\r\n# SaaS Accounting & Invoicing Platform\r\n\r\nThis project is a cloud‑based accounting and invoicing solution designed for small businesses. It provides a modern user experience for creating invoices, tracking payments and managing a ledger, all built on top of a Next.js frontend and a Postgres database. To support ongoing development, the platform adopts pragmatic CI/CD and observability practices, ensuring that updates are delivered quickly and reliably. Key aspects include:\r\n\r\n- **Fast invoicing workflows** – generate professional invoices in seconds and track their status across the client lifecycle.\r\n- **Clean ledger management** – maintain an organized record of transactions and automatically reconcile payments.\r\n- **Modern tech stack** – Next.js offers server‑side rendering and API routes, while Postgres provides transactional integrity.\r\n- **Infrastructure** – built with CI/CD pipelines and monitoring to catch issues early and roll out features without downtime.\r\n\r\nAs an ongoing freelance project, the platform demonstrates how web technologies can simplify financial operations for small businesses.\r\n",
    "contentHtml": "<h1>SaaS Accounting &#x26; Invoicing Platform</h1>\n<p>This project is a cloud‑based accounting and invoicing solution designed for small businesses. It provides a modern user experience for creating invoices, tracking payments and managing a ledger, all built on top of a Next.js frontend and a Postgres database. To support ongoing development, the platform adopts pragmatic CI/CD and observability practices, ensuring that updates are delivered quickly and reliably. Key aspects include:</p>\n<ul>\n<li><strong>Fast invoicing workflows</strong> – generate professional invoices in seconds and track their status across the client lifecycle.</li>\n<li><strong>Clean ledger management</strong> – maintain an organized record of transactions and automatically reconcile payments.</li>\n<li><strong>Modern tech stack</strong> – Next.js offers server‑side rendering and API routes, while Postgres provides transactional integrity.</li>\n<li><strong>Infrastructure</strong> – built with CI/CD pipelines and monitoring to catch issues early and roll out features without downtime.</li>\n</ul>\n<p>As an ongoing freelance project, the platform demonstrates how web technologies can simplify financial operations for small businesses.</p>\n",
    "image": "",
    "technologies": [],
    "githubUrl": "",
    "liveUrl": "",
    "date": "2025-09-13",
    "category": "Software Development",
    "featured": true
  },
  {
    "slug": "react-native-app",
    "title": "React Native App",
    "excerpt": "A cross‑platform mobile application under active development, delivering a lean feature set and a consistent user experience through shared UI primitives.",
    "content": "\r\n# React Native App\r\n\r\nThis React Native project aims to deliver a lean, fast mobile application that works across both iOS and Android devices. By sharing UI primitives and business logic, the app achieves consistent look and feel on different platforms【835914650520473†L65-L69】. The initial feature set focuses on core functionality while leaving room for rapid iteration as user feedback is gathered. Highlights include:\r\n\r\n- **Cross‑platform codebase** – React Native enables the majority of the code to run on both platforms while still allowing platform‑specific enhancements.\r\n- **Shared components** – reusable UI primitives promote consistency and reduce development time【835914650520473†L65-L69】.\r\n- **Performance** – careful attention to state management and network requests ensures that the app feels responsive on a wide range of devices.\r\n- **Scalability** – the architecture is designed to accommodate future features without major rewrites.\r\n\r\nThis project showcases the advantages of building native‑like experiences using a single JavaScript/TypeScript codebase.\r\n",
    "contentHtml": "<h1>React Native App</h1>\n<p>This React Native project aims to deliver a lean, fast mobile application that works across both iOS and Android devices. By sharing UI primitives and business logic, the app achieves consistent look and feel on different platforms【835914650520473†L65-L69】. The initial feature set focuses on core functionality while leaving room for rapid iteration as user feedback is gathered. Highlights include:</p>\n<ul>\n<li><strong>Cross‑platform codebase</strong> – React Native enables the majority of the code to run on both platforms while still allowing platform‑specific enhancements.</li>\n<li><strong>Shared components</strong> – reusable UI primitives promote consistency and reduce development time【835914650520473†L65-L69】.</li>\n<li><strong>Performance</strong> – careful attention to state management and network requests ensures that the app feels responsive on a wide range of devices.</li>\n<li><strong>Scalability</strong> – the architecture is designed to accommodate future features without major rewrites.</li>\n</ul>\n<p>This project showcases the advantages of building native‑like experiences using a single JavaScript/TypeScript codebase.</p>\n",
    "image": "",
    "technologies": [],
    "githubUrl": "",
    "liveUrl": "",
    "date": "2025-09-13",
    "category": "Mobile Development",
    "featured": true
  },
  {
    "slug": "kidcentral-realsense-dimensioner",
    "title": "Kidcentral Realsense Dimensioner",
    "excerpt": "A desktop application that uses Intel RealSense depth cameras to capture and compute object dimensions, packaging C# and OpenCV into a reliable tool for precise measurement.",
    "content": "\r\n# Kidcentral Realsense Dimensioner\r\n\r\nKidcentral Realsense Dimensioner is a Windows desktop tool that captures the physical dimensions of objects using Intel RealSense depth cameras. Leveraging C#, OpenCV and the Intel RealSense SDK, the application measures length, width and height from depth data and packages the results into a user‑friendly interface. Highlights of the project include:\r\n\r\n- **Depth‑camera integration** – the tool streams point‑cloud data from Intel RealSense cameras and processes it in real time.\r\n- **Accurate measurement** – OpenCV algorithms calculate dimensions and compensate for camera distortion and perspective.\r\n- **Reliable deployments** – packaged installers make it easy to deploy the software across the organization for consistent performance.\r\n- **Use cases** – warehouse staff can quickly dimension packages for shipping, and product teams can measure prototypes without specialized hardware.\r\n\r\nBy combining computer‑vision techniques with off‑the‑shelf hardware, this project provides a cost‑effective alternative to expensive industrial dimensioning systems.\r\n",
    "contentHtml": "<h1>Kidcentral Realsense Dimensioner</h1>\n<p>Kidcentral Realsense Dimensioner is a Windows desktop tool that captures the physical dimensions of objects using Intel RealSense depth cameras. Leveraging C#, OpenCV and the Intel RealSense SDK, the application measures length, width and height from depth data and packages the results into a user‑friendly interface. Highlights of the project include:</p>\n<ul>\n<li><strong>Depth‑camera integration</strong> – the tool streams point‑cloud data from Intel RealSense cameras and processes it in real time.</li>\n<li><strong>Accurate measurement</strong> – OpenCV algorithms calculate dimensions and compensate for camera distortion and perspective.</li>\n<li><strong>Reliable deployments</strong> – packaged installers make it easy to deploy the software across the organization for consistent performance.</li>\n<li><strong>Use cases</strong> – warehouse staff can quickly dimension packages for shipping, and product teams can measure prototypes without specialized hardware.</li>\n</ul>\n<p>By combining computer‑vision techniques with off‑the‑shelf hardware, this project provides a cost‑effective alternative to expensive industrial dimensioning systems.</p>\n",
    "image": "",
    "technologies": [
      "C#",
      "OpenCV",
      "Intel RealSense",
      "Desktop"
    ],
    "githubUrl": "",
    "liveUrl": "",
    "date": "2025-09-13",
    "category": "Software Development",
    "featured": true
  },
  {
    "slug": "kidcentral-analytics-internal-apps",
    "title": "Kidcentral Analytics & Internal Apps",
    "excerpt": "Secure dashboards and internal systems that replace outsourced e‑commerce integrations, providing role‑based access to ERP and operational data and reducing deployment times from months to days.",
    "content": "\r\n# Kidcentral Analytics & Internal Apps\r\n\r\nTo give managers immediate access to operational insights, Aayush built secure dashboards powered by ERP and operational data. These dashboards use role‑based access control so that each team sees only the information relevant to them. By replacing outsourced e‑commerce integrations with reusable internal systems, the project reduced costs, improved transparency and cut deployment times from months to days. The solution uses PocketBase for authentication, a Python/FastAPI backend and a React front end.\r\n\r\nKey benefits include:\r\n\r\n- **Immediate insights** – live dashboards surface sales, inventory and operational metrics.\r\n- **Rapid deployment** – new integrations can be deployed in minutes rather than months.\r\n- **Lower costs** – eliminating vendor fees and contracts saves money and increases control.\r\n- **CI/CD pipeline** – automated testing and deployment ensure reliability and speed.\r\n\r\nBy internalizing analytics and integrations, the company gained control over its data and improved its ability to respond quickly to business needs.\r\n",
    "contentHtml": "<h1>Kidcentral Analytics &#x26; Internal Apps</h1>\n<p>To give managers immediate access to operational insights, Aayush built secure dashboards powered by ERP and operational data. These dashboards use role‑based access control so that each team sees only the information relevant to them. By replacing outsourced e‑commerce integrations with reusable internal systems, the project reduced costs, improved transparency and cut deployment times from months to days. The solution uses PocketBase for authentication, a Python/FastAPI backend and a React front end.</p>\n<p>Key benefits include:</p>\n<ul>\n<li><strong>Immediate insights</strong> – live dashboards surface sales, inventory and operational metrics.</li>\n<li><strong>Rapid deployment</strong> – new integrations can be deployed in minutes rather than months.</li>\n<li><strong>Lower costs</strong> – eliminating vendor fees and contracts saves money and increases control.</li>\n<li><strong>CI/CD pipeline</strong> – automated testing and deployment ensure reliability and speed.</li>\n</ul>\n<p>By internalizing analytics and integrations, the company gained control over its data and improved its ability to respond quickly to business needs.</p>\n",
    "image": "",
    "technologies": [
      "ERP",
      "Dashboards",
      "PocketBase",
      "Python",
      "React",
      "FastAPI",
      "CI/CD"
    ],
    "githubUrl": "",
    "liveUrl": "",
    "date": "2025-09-13",
    "category": "DevOps",
    "featured": true
  },
  {
    "slug": "kidcentral-analytics-dashboard",
    "title": "Kidcentral Analytics Dashboard",
    "excerpt": "Company-wide analytics web app delivering secure access and actionable operational insights with a fast React UI and PocketBase authentication.",
    "content": "\r\n# Kidcentral Analytics Dashboard\r\n\r\nKidcentral Analytics Dashboard is a secure, company‑wide analytics application that exposes operational data to managers and team members. Built with a fast Vite‑powered React frontend and a Python service behind PocketBase authentication, it delivers live charts and tables that help the business make data‑driven decisions. The dashboard provides role‑based access control, ensuring that sensitive information is shared appropriately while still being easy to use. Key features include:\r\n\r\n- **Secure authentication** – PocketBase handles user sign‑ups, logins and permissions, while the Python backend serves pre‑processed analytics data.\r\n- **Fast user experience** – a Vite + React UI renders charts and tables quickly, allowing managers to drill into sales and inventory metrics without delays.\r\n- **Scalable architecture** – the separation of frontend and backend components enables independent scaling and simplifies maintenance.\r\n- **Actionable insights** – real‑time data visualizations make it easy to spot trends, anomalies and growth opportunities.\r\n\r\nThis project demonstrates how modern web technologies can turn raw business data into operational intelligence. It lays the groundwork for further enhancements such as self‑service reporting and predictive analytics.\r\n",
    "contentHtml": "<h1>Kidcentral Analytics Dashboard</h1>\n<p>Kidcentral Analytics Dashboard is a secure, company‑wide analytics application that exposes operational data to managers and team members. Built with a fast Vite‑powered React frontend and a Python service behind PocketBase authentication, it delivers live charts and tables that help the business make data‑driven decisions. The dashboard provides role‑based access control, ensuring that sensitive information is shared appropriately while still being easy to use. Key features include:</p>\n<ul>\n<li><strong>Secure authentication</strong> – PocketBase handles user sign‑ups, logins and permissions, while the Python backend serves pre‑processed analytics data.</li>\n<li><strong>Fast user experience</strong> – a Vite + React UI renders charts and tables quickly, allowing managers to drill into sales and inventory metrics without delays.</li>\n<li><strong>Scalable architecture</strong> – the separation of frontend and backend components enables independent scaling and simplifies maintenance.</li>\n<li><strong>Actionable insights</strong> – real‑time data visualizations make it easy to spot trends, anomalies and growth opportunities.</li>\n</ul>\n<p>This project demonstrates how modern web technologies can turn raw business data into operational intelligence. It lays the groundwork for further enhancements such as self‑service reporting and predictive analytics.</p>\n",
    "image": "",
    "technologies": [
      "Analytics",
      "React",
      "Vite",
      "PocketBase",
      "Python"
    ],
    "githubUrl": "",
    "liveUrl": "",
    "date": "2025-09-13",
    "category": "Software Development",
    "featured": true
  }
];

export const generatedAt = "2025-12-04T23:23:46.622Z";
